{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT media_id)|\n",
      "+------------------------+\n",
      "|                27093348|\n",
      "+------------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                1246295|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "#from pyspark.sql.functions import *\n",
    "from pyspark.sql import functions as F\n",
    "#from googletrans import Translator\n",
    "from pyspark.sql.window import Window\n",
    "from pyspark.sql.types import TimestampType\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.mlab as mlab\n",
    "#from mpl_toolkits.basemap import Basemap\n",
    "import time\n",
    "    \n",
    "spark = SparkSession \\\n",
    "    .builder \\\n",
    "    .appName(\"Large scale human mobility data analysis through social media\") \\\n",
    "    .config(\"spark.sql.broadcastTimeout\", \"36000\") \\\n",
    "    .getOrCreate()\n",
    "    \n",
    "twitter_df = spark.read.load(\"/data/twitterdata/twitter2018*.parquet\", format=\"parquet\")\n",
    "twitter_df = twitter_df.dropDuplicates(['media_id'])\n",
    "twitter_df.createOrReplaceTempView(\"twitter\")\n",
    "twitter_df = spark.sql(\"select * from twitter where user_id in (select distinct user_id from twitter where country_code in ('BE','BG','CZ','DK','DE','EE','IE','EL','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE','UK','IS','LI','NO','CH','ME','MK','AL','RS','TR','XK','BA'))\")\n",
    "twitter_df.agg(F.countDistinct(\"media_id\")).show()\n",
    "twitter_df.agg(F.countDistinct(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT media_id)|\n",
      "+------------------------+\n",
      "|                 5540371|\n",
      "+------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "twitter_geotagged = twitter_df.filter(twitter_df['lat'].isNotNull())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.20449192916283362"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "5540371/27093348"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT media_id)|\n",
      "+------------------------+\n",
      "|                  452613|\n",
      "+------------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                  23805|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instagram_user_df = spark.read.load(\"/data/instagramdata/instagram_user2018*.parquet\", format=\"parquet\")\n",
    "instagram_media1 = spark.read.load(\"/data/instagramdata/instagram_media2018*.parquet\", format=\"parquet\")\n",
    "instagram_media2 = spark.read.load(\"/data/instagramdata1/instagram_media2018*.parquet\", format=\"parquet\")\n",
    "instagram_media_df = instagram_media1.union(instagram_media2)\n",
    "instagram_location_df = spark.read.load(\"/data/instagramdata/instagram_location2018_04*.parquet\", format=\"parquet\")\n",
    "\n",
    "user_media_df = instagram_user_df.join(instagram_media_df,instagram_user_df[\"user_id\"] == instagram_media_df[\"user_id\"]).drop(instagram_media_df[\"user_id\"])\n",
    "instagram_df = user_media_df.join(instagram_location_df,user_media_df[\"location_id\"] == instagram_location_df[\"location_id\"]).drop(instagram_location_df[\"location_id\"])\n",
    "instagram_df = instagram_df.dropDuplicates(['media_id'])\n",
    "instagram_df.createOrReplaceTempView(\"instagram\")\n",
    "instagram_df = spark.sql(\"select * from instagram where user_id in (select distinct user_id from instagram where country_id in ('BE','BG','CZ','DK','DE','EE','IE','EL','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE','UK','IS','LI','NO','CH','ME','MK','AL','RS','TR','XK','BA'))\")\n",
    "#instagram_df.write.save(\"/data/instagramdata/instagram10_11.parquet\",format=\"parquet\",mode='overwrite')\n",
    "instagram_df.agg(F.countDistinct(\"media_id\")).show()\n",
    "instagram_df.agg(F.countDistinct(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# great-circle distance calculation function\n",
    "# def dist(long_x, lat_x, long_y, lat_y):\n",
    "#    return F.acos(\n",
    "#        F.sin(F.radians(lat_x)) * F.sin(F.radians(lat_y)) +\n",
    "#        F.cos(F.radians(lat_x)) * F.cos(F.radians(lat_y)) *\n",
    "#            F.cos(F.radians(long_x) - F.radians(long_y))\n",
    "#    ) * F.lit(6371.0)\n",
    "\n",
    "# Haversine formula distance calculation function\n",
    "def dist(lon1, lat1, lon2, lat2):\n",
    "    radius = 6371  # km\n",
    "    dlat = F.radians(lat2 - lat1)\n",
    "    dlon = F.radians(lon2 - lon1)\n",
    "    a = F.sin(dlat / 2) * F.sin(dlat / 2) + F.cos(F.radians(lat1)) \\\n",
    "        * F.cos(F.radians(lat2)) * F.sin(dlon / 2) * F.sin(dlon / 2)\n",
    "    c = 2 * F.atan2(F.sqrt(a), F.sqrt(1 - a))\n",
    "    d = radius * c\n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot interarrivaltime and interdistance and filter tweet whose speed<= 1000 km/h\n",
    "\n",
    "changeDateStructure_udf = F.udf(\n",
    "    lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.strptime(x, '%a %b %d %H:%M:%S +0000 %Y')))\n",
    "twitter_df = twitter_df.withColumn(\"create_time\",\n",
    "                                   F.to_timestamp(changeDateStructure_udf(\"create_time\"), 'yyyy-MM-dd HH:mm:ss').alias(\n",
    "                                       \"create_time\"))\n",
    "\n",
    "# calculate interval distance between consecutive create_time\n",
    "w = Window().partitionBy(twitter_df[\"user_id\"]).orderBy(twitter_df[\"create_time\"])\n",
    "\n",
    "#distance is NaA when using great-circle distance calculation to calculate two equal coordinates\n",
    "# geodistance_df = twitter_df.withColumn(\"dist\", (when((twitter_df[\"place_lon\"]==lag(twitter_df[\"place_lon\"], 1).over(w))&(twitter_df[\"place_lat\"]==lag(twitter_df[\"place_lat\"],1).over(w)),lit(0.0)).otherwise(dist(\n",
    "#    twitter_df[\"place_lon\"], twitter_df[\"place_lat\"],\n",
    "#    lag(twitter_df[\"place_lon\"], 1).over(w), lag(twitter_df[\"place_lat\"], 1).over(w)\n",
    "# ))).alias(\"dist\"))\n",
    "\n",
    "twitter_df = twitter_df.withColumn(\"dist\", dist(\n",
    "    twitter_df[\"place_lon\"], twitter_df[\"place_lat\"],\n",
    "    F.lag(twitter_df[\"place_lon\"], 1).over(w), F.lag(twitter_df[\"place_lat\"], 1).over(w)\n",
    ").alias(\"dist\"))\n",
    "# calculate timeDiff by day\n",
    "# w = Window().partitionBy(geodistance_df[\"user_id\"]).orderBy(geodistance_df[\"create_time\"])\n",
    "# time_space_df = geodistance_df.withColumn(\"interarrivaltime\", datediff(geodistance_df[\"create_time\"],lag(geodistance_df[\"create_time\"], 1).over(w)).alias(\"interarrivaltime\"))\n",
    "\n",
    "# calulate timeDiff by second\n",
    "twitter_df = twitter_df.withColumn(\"interarrivaltime\", (\n",
    "        F.unix_timestamp(twitter_df[\"create_time\"]) - F.unix_timestamp(\n",
    "    F.lag(twitter_df[\"create_time\"], 1).over(w))).alias(\"interarrivaltime\"))\n",
    "\n",
    "#time_space_df = time_space_df.filter(time_space_df[\"interarrivaltime\"].isNotNull())\n",
    "twitter_df = twitter_df.filter((twitter_df['interarrivaltime'] != 0)|(twitter_df['interarrivaltime'].isNull()))\n",
    "twitter_df = twitter_df.withColumn(\"speed\",(twitter_df['dist'] * 3600 / twitter_df['interarrivaltime']).alias(\"speed\"))\n",
    "twitter_df = twitter_df.filter((twitter_df[\"speed\"]<= 1000)|(twitter_df[\"speed\"].isNull()))\n",
    "\n",
    "#twitter_speed_exclusion = twitter_df.select(twitter_df['user_id'],twitter_df['speed'],twitter_df['media_id'],F.lag(twitter_df[\"media_id\"], 1).over(w).alias('p_media_id')).filter(F.col('speed')>1000)\n",
    "#twitter_speed_exclusion = twitter_speed_exclusion.select(['media_id']).union(twitter_speed_exclusion.select(['p_media_id']))\n",
    "#witter_speed_exclusion.createOrReplaceTempView(\"twitter_speed_exclusion\")\n",
    "#twitter_df = spark.sql(\"select * from twitter where media_id not in (select media_id from twitter_speed_exclusion)\")\n",
    "\n",
    "twitter_df.agg(F.countDistinct(\"media_id\")).show()\n",
    "twitter_df.agg(F.countDistinct(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------------+\n",
      "|count(DISTINCT media_id)|\n",
      "+------------------------+\n",
      "|                  443102|\n",
      "+------------------------+\n",
      "\n",
      "+-----------------------+\n",
      "|count(DISTINCT user_id)|\n",
      "+-----------------------+\n",
      "|                  23805|\n",
      "+-----------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "instagram_df = instagram_df.withColumn('create_time',instagram_df['create_time_stamp'].cast(TimestampType()))\n",
    "\n",
    "w = Window().partitionBy(instagram_df[\"user_id\"]).orderBy(instagram_df[\"create_time\"])\n",
    "\n",
    "instagram_df = instagram_df.withColumn(\"dist\", dist(\n",
    "    instagram_df[\"lon\"], instagram_df[\"lat\"],\n",
    "    F.lag(instagram_df[\"lon\"], 1).over(w), F.lag(instagram_df[\"lat\"], 1).over(w)\n",
    ").alias(\"dist\"))\n",
    "\n",
    "# calulate timeDiff by second\n",
    "instagram_df = instagram_df.withColumn(\"interarrivaltime\", (\n",
    "        F.unix_timestamp(instagram_df[\"create_time\"]) - F.unix_timestamp(\n",
    "    F.lag(instagram_df[\"create_time\"], 1).over(w))).alias(\"interarrivaltime\"))\n",
    "instagram_df = instagram_df.filter((instagram_df['interarrivaltime'] != 0)|(instagram_df['interarrivaltime'].isNull()))\n",
    "instagram_df = instagram_df.withColumn(\"speed\",(instagram_df['dist'] * 3600 / instagram_df['interarrivaltime']).alias(\"speed\"))\n",
    "instagram_df = instagram_df.filter((instagram_df[\"speed\"]<= 1000)|(instagram_df[\"speed\"].isNull()))\n",
    "#exclude two consecutive media that imply user relocating with a speed more than 1000km/h\n",
    "instagram_df.createOrReplaceTempView(\"instagram\")\n",
    "#instagram_speed_exclusion = instagram_df.select(instagram_df['user_id'],instagram_df['speed'],instagram_df['media_id'],F.lag(instagram_df[\"media_id\"], 1).over(w).alias('p_media_id')).filter(F.col('speed')>1000)\n",
    "#instagram_speed_exclusion = instagram_speed_exclusion.select(['media_id']).union(instagram_speed_exclusion.select(['p_media_id']))\n",
    "#instagram_speed_exclusion.createOrReplaceTempView(\"instagram_speed_exclusion\")\n",
    "#instagram_df = spark.sql(\"select * from instagram where media_id not in (select media_id from instagram_speed_exclusion)\")\n",
    "#instagram_df = spark.sql(\"select * from instagram where user_id not in (select user_id from instagram where speed >1000)\")\n",
    "#\n",
    "#instagram_df = instagram_df.filter(instagram_df['media_id'].isin(instagram_speed_exclusion['media_id'])==False)\n",
    "#instagram_df = instagram_df.filter(instagram_df['country_id'].isin(['BE','BG','CZ','DK','DE','EE','IE','EL','ES','FR','HR','IT','CY','LV','LT','LU','HU','MT','NL','AT','PL','PT','RO','SI','SK','FI','SE','UK','IS','LI','NO','CH','ME','MK','AL','RS','TR','XK','BA']))\n",
    "#instagram_df.write.save(\"/data/instagramdata/instagram_df.parquet\",format=\"parquet\",mode='overwrite')\n",
    "instagram_df.agg(F.countDistinct(\"media_id\")).show()\n",
    "instagram_df.agg(F.countDistinct(\"user_id\")).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "twitter_df.write.save(\"/data/twitterdata/UserTweetInEurope_df.parquet\",format=\"parquet\",mode='overwrite')\n",
    "instagram_df.write.save(\"/data/instagramdata/instagram_df.parquet\",format=\"parquet\",mode='overwrite')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
